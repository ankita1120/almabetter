{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ankita1120/almabetter/blob/publicBranch/Copy_of_Numerical_Programming_in_Python_Web_Scraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKFlk3slQ1ol"
      },
      "source": [
        "# **Web Scraping & Data Handling Challenge**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YU_opgaCYpcO"
      },
      "source": [
        "\n",
        "\n",
        "### **Website:**\n",
        "JustWatch -  https://www.justwatch.com/in/movies?release_year_from=2000\n",
        "\n",
        "\n",
        "### **Description:**\n",
        "\n",
        "JustWatch is a popular platform that allows users to search for movies and TV shows across multiple streaming services like Netflix, Amazon Prime, Hulu, etc. For this assignment, you will be required to scrape movie and TV show data from JustWatch using Selenium, Python, and BeautifulSoup. Extract data from HTML, not by directly calling their APIs. Then, perform data filtering and analysis using Pandas, and finally, save the results to a CSV file.\n",
        "\n",
        "### **Tasks:**\n",
        "\n",
        "**1. Web Scraping:**\n",
        "\n",
        "Use BeautifulSoup to scrape the following data from JustWatch:\n",
        "\n",
        "   **a. Movie Information:**\n",
        "\n",
        "      - Movie title\n",
        "      - Release year\n",
        "      - Genre\n",
        "      - IMDb rating\n",
        "      - Streaming services available (Netflix, Amazon Prime, Hulu, etc.)\n",
        "      - URL to the movie page on JustWatch\n",
        "\n",
        "   **b. TV Show Information:**\n",
        "\n",
        "      - TV show title\n",
        "      - Release year\n",
        "      - Genre\n",
        "      - IMDb rating\n",
        "      - Streaming services available (Netflix, Amazon Prime, Hulu, etc.)\n",
        "      - URL to the TV show page on JustWatch\n",
        "\n",
        "  **c. Scope:**\n",
        "\n",
        "```\n",
        " ` - Scrape data for at least 50 movies and 50 TV shows.\n",
        "   - You can choose the entry point (e.g., starting with popular movies,\n",
        "     or a specific genre, etc.) to ensure a diverse dataset.`\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "**2. Data Filtering & Analysis:**\n",
        "\n",
        "   After scraping the data, use Pandas to perform the following tasks:\n",
        "\n",
        "   **a. Filter movies and TV shows based on specific criteria:**\n",
        "\n",
        "   ```\n",
        "      - Only include movies and TV shows released in the last 2 years (from the current date).\n",
        "      - Only include movies and TV shows with an IMDb rating of 7 or higher.\n",
        "```\n",
        "\n",
        "   **b. Data Analysis:**\n",
        "\n",
        "   ```\n",
        "      - Calculate the average IMDb rating for the scraped movies and TV shows.\n",
        "      - Identify the top 5 genres that have the highest number of available movies and TV shows.\n",
        "      - Determine the streaming service with the most significant number of offerings.\n",
        "      \n",
        "   ```   \n",
        "\n",
        "**3. Data Export:**\n",
        "\n",
        "```\n",
        "   - Dump the filtered and analysed data into a CSV file for further processing and reporting.\n",
        "\n",
        "   - Keep the CSV file in your Drive Folder and Share the Drive link on the colab while keeping view access with anyone.\n",
        "```\n",
        "\n",
        "**Submission:**\n",
        "```\n",
        "- Submit a link to your Colab made for the assignment.\n",
        "\n",
        "- The Colab should contain your Python script (.py format only) with clear\n",
        "  comments explaining the scraping, filtering, and analysis process.\n",
        "\n",
        "- Your Code shouldn't have any errors and should be executable at a one go.\n",
        "\n",
        "- Before Conclusion, Keep your Dataset Drive Link in the Notebook.\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "**Note:**\n",
        "\n",
        "1. Properly handle errors and exceptions during web scraping to ensure a robust script.\n",
        "\n",
        "2. Make sure your code is well-structured, easy to understand, and follows Python best practices.\n",
        "\n",
        "3. The assignment will be evaluated based on the correctness of the scraped data, accuracy of data filtering and analysis, and the overall quality of the Python code.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8ptoMlNQ5zB"
      },
      "source": [
        "# **Start The Project**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xHLaFLPn4yC"
      },
      "source": [
        "## **Task 1:- Web Scrapping**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axiEsy9ZL3qd",
        "outputId": "adc12816-5453-46d7-f560-fefd49d85393"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting bs4\n",
            "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from bs4) (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->bs4) (2.6)\n",
            "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
            "Installing collected packages: bs4\n",
            "Successfully installed bs4-0.0.2\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2024.12.14)\n"
          ]
        }
      ],
      "source": [
        "#Installing all necessary labraries\n",
        "!pip install bs4\n",
        "!pip install requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "omJlLZASQBmU"
      },
      "outputs": [],
      "source": [
        "#import all necessary labraries\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCWbwB1Og3bD"
      },
      "source": [
        "## **Scrapping Movies Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nPDgza5mQJKr",
        "outputId": "80dd9fcb-59d1-47c5-d150-72b04b12e595"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Movie data scraping complete and saved to '/content/drive/My Drive/movie_data.csv'.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "url = 'https://www.justwatch.com/in/movies?release_year_from=2000'\n",
        "\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'\n",
        "}\n",
        "\n",
        "response = requests.get(url, headers=headers)\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "movie_links = soup.find_all('a', href=True)\n",
        "movie_urls = [link['href'] for link in movie_links if '/movie/' in link['href']]\n",
        "url_list = ['https://www.justwatch.com' + x for x in movie_urls]\n",
        "\n",
        "movie_data = []\n",
        "\n",
        "for movie_url in url_list:\n",
        "    response = requests.get(movie_url, headers=headers)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    title = soup.find('h1').text.strip() if soup.find('h1') else 'N/A'\n",
        "    release_year = soup.find('span', class_='release-year').text.strip() if soup.find('span', class_='release-year') else 'N/A'\n",
        "    imdb_rating = soup.find('span', class_='imdb-score').text.strip().split(' ')[0] if soup.find('span', class_='imdb-score') else 'N/A'\n",
        "\n",
        "    streaming_services = []\n",
        "    service_tags = soup.find_all('a', class_='offer')\n",
        "    for tag in service_tags:\n",
        "        img = tag.find('img')\n",
        "        service = img['alt'].strip() if img and 'alt' in img.attrs else 'N/A'\n",
        "        streaming_services.append(service)\n",
        "\n",
        "    movie_data.append({\n",
        "        'Title': title,\n",
        "        'Release Year': release_year,\n",
        "        'IMDb Rating': imdb_rating,\n",
        "        'Streaming Services': ', '.join(streaming_services)\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(movie_data)\n",
        "\n",
        "output_path = '/content/drive/My Drive/movie_data.csv'\n",
        "df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"Movie data scraping complete and saved to '{output_path}'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-qsNrtIsBEp"
      },
      "source": [
        "### **Fetching Movie URL's**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5O1VDHCQn-Xr",
        "outputId": "578b33f5-7d68-4f30-89b1-2c7c25d6a297"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Movie URLs have been scraped and saved to '/content/drive/My Drive/movie_url.csv'.\n",
            "A total of 110 movie URLs were found.\n",
            "Sample URLs: ['/in/movie/pushpa-the-rule-part-2', '/in/movie/marco-2024', '/in/movie/sookshma-darshini', '/in/movie/ore-dake-level-up-na-ken-reawakening', '/in/movie/bhool-bhulaiyaa-3']\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "drive.mount ('/content/drive')\n",
        "\n",
        "# Base URL for movie listings\n",
        "url = 'https://www.justwatch.com/in/movies?release_year_from=2000'\n",
        "headers ={\n",
        "    'User-Agent': 'Mozilla/5.0(Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'\n",
        "}\n",
        "response = requests.get(url,headers=headers)\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# Find all movie links and build full URLs\n",
        "movie_links = soup.find_all('a', href=True)\n",
        "movie_urls = [link['href'] for link in movie_links if '/movie/' in link['href']]\n",
        "url_list = ['https://www.justwatch.com' + x for x in movie_urls]\n",
        "\n",
        "movie_url_df = pd.DataFrame({'Movie URL': url_list})\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "movie_url_df.to_csv('/content/drive/My Drive/movie_url.csv', index=False)\n",
        "\n",
        "# More informative print statement\n",
        "print(f\"Movie URLs have been scraped and saved to '/content/drive/My Drive/movie_url.csv'.\")\n",
        "print(f\"A total of {len(movie_urls)} movie URLs were found.\")\n",
        "# Optionally, print a few sample URLs:\n",
        "print(f\"Sample URLs: {movie_urls[:5]}\")  # Prints the first 5 URLs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEg1U1uPzGoj"
      },
      "source": [
        "## **Scrapping release Year**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "fsZmROMfoxKd",
        "outputId": "c78b30c4-c5d4-42ca-e8bf-bec9ba20899c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Release years have been scraped and saved to 'movie_release_years.csv'.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set the URL and headers\n",
        "url = 'https://www.justwatch.com/in/movies?release_year_from=2000'\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'\n",
        "}\n",
        "\n",
        "# Fetch the main page\n",
        "response = requests.get(url, headers=headers)\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# Extract movie URLs\n",
        "movie_links = soup.find_all('a', href=True)\n",
        "movie_urls = [link['href'] for link in movie_links if '/movie/' in link['href']]\n",
        "url_list = ['https://www.justwatch.com' + x for x in movie_urls]\n",
        "\n",
        "# Initialize storage for release years\n",
        "release_years = []\n",
        "\n",
        "# Scrape each movie page\n",
        "for movie_url in url_list:\n",
        "    try:\n",
        "        response = requests.get(movie_url, headers=headers)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Extract release year\n",
        "        year_tag = soup.find('span', class_='release-year')\n",
        "        release_year = year_tag.text.strip() if year_tag else 'N/A'\n",
        "        release_years.append(release_year)\n",
        "\n",
        "        # Respect server limits\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching {movie_url}: {e}\")\n",
        "        release_years.append('Error')\n",
        "\n",
        "# Save to DataFrame and CSV\n",
        "df = pd.DataFrame({'release_year': release_years})\n",
        "df.to_csv('/content/drive/My Drive/movie_release_years.csv', index=False)\n",
        "\n",
        "print(\"Release years have been scraped and saved to 'movie_release_years.csv'.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqzhL8STqaMX"
      },
      "source": [
        "## **Scrapping Genres**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "aeES8EFUtziM",
        "outputId": "92f914fe-7c15-4662-e409-45583401fb5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'find_all'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-c9471568c6c9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# Extract genres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mdiv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'div'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'title-info title-info'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mspan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'span'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mgenre_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mspan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "from google.colab import files\n",
        "\n",
        "# Mount Google Drive (if in Google Colab)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# URL to scrape\n",
        "url = 'https://www.justwatch.com/in/movies?release_year_from=2000'\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'\n",
        "}\n",
        "\n",
        "# Initial request to fetch the main page\n",
        "response = requests.get(url, headers=headers)\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# Extract movie URLs\n",
        "movie_links = soup.find_all('a', href=True)\n",
        "movie_urls = [link['href'] for link in movie_links if '/movie/' in link['href']]\n",
        "url_list = ['https://www.justwatch.com' + x for x in movie_urls]\n",
        "\n",
        "# Initialize genres list\n",
        "genres = []\n",
        "\n",
        "# Loop through movie URLs to scrape genres\n",
        "for movie_url in url_list:\n",
        "    response = requests.get(movie_url, headers=headers)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Extract genres\n",
        "    div = soup.find('div', class_='title-info title-info')\n",
        "    span = div.find_all('span')\n",
        "    genre_list = []\n",
        "    for tag in span:\n",
        "        genre = tag.text.strip() if tag else 'N/A'\n",
        "        genre_list.append(genre)\n",
        "    genres.append(', '.join(genre_list))\n",
        "df = pd.DataFrame({'Genre': genres})\n",
        "df.to_csv('/content/drive/My Drive/movie_genres.csv', index=False)\n",
        "\n",
        "print(\"Genres have been scraped and saved to 'movie_genres.csv'.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOof6-0xFuf6"
      },
      "source": [
        "## **Scrapping IMBD Rating**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gW467MLx6aCH"
      },
      "outputs": [],
      "source": [
        "# Write Your Code here\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "import time\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# URL of the JustWatch page to scrape\n",
        "url = 'https://www.justwatch.com/in/movies?release_year_from=2000'\n",
        "\n",
        "# Headers to mimic a web browser\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'\n",
        "}\n",
        "\n",
        "# Get the HTML content of the page\n",
        "response = requests.get(url, headers=headers)\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# Find all movie links\n",
        "movie_links = soup.find_all('a', href=True)\n",
        "\n",
        "# Extract movie URLs that contain '/movie/'\n",
        "movie_urls = [link['href'] for link in movie_links if '/movie/' in link['href']]\n",
        "\n",
        "# Add the base URL to each movie URL\n",
        "url_list = ['https://www.justwatch.com' + x for x in movie_urls]\n",
        "\n",
        "# List to store IMDb ratings\n",
        "imdb_ratings = []\n",
        "\n",
        "# Loop through each movie URL and extract the IMDb rating\n",
        "for movie_url in url_list:\n",
        "    response = requests.get(movie_url, headers=headers)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Find the element containing the IMDb rating using its class\n",
        "    rating_tag = soup.find('span', class_='imdb-score')\n",
        "\n",
        "    # Extract the rating or 'N/A' if not found\n",
        "    imdb_ratings.append(rating_tag.text.strip().split(' ')[0] if rating_tag else 'N/A')\n",
        "# Create a Pandas DataFrame to store the ratings\n",
        "df = pd.DataFrame({'IMDb Rating': imdb_ratings})\n",
        "\n",
        "# Save the DataFrame to a CSV file on Google Drive\n",
        "df.to_csv('/content/drive/My Drive/movie_imdb_ratings.csv', index=False)\n",
        "\n",
        "print(\"IMDb ratings have been scraped and saved to 'tv_imdb_ratings.csv'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CHiu0A5RAuM"
      },
      "source": [
        "## **Scrapping Runtime/Duration**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "si_yaGO8OTBo"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# Mount Google Drive (if in Google Colab)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "url = 'https://www.justwatch.com/in/movies?release_year_from=2000'\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'\n",
        "}\n",
        "\n",
        "# Fetch the main page and parse\n",
        "response = requests.get(url, headers=headers)\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# Extract movie links\n",
        "movie_links = soup.find_all('a', href=True)\n",
        "movie_urls = [link['href'] for link in movie_links if '/movie/' in link['href']]\n",
        "url_list = ['https://www.justwatch.com' + x for x in movie_urls]\n",
        "\n",
        "# Initialize a list to store data\n",
        "runtime_data = []\n",
        "\n",
        "# Scrape runtime for each movie\n",
        "for movie_url in url_list:\n",
        "    try:\n",
        "        response = requests.get(movie_url, headers=headers)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Extract runtime (adjust the class as needed)\n",
        "        runtime_tag = soup.find('div', class_='title-detail-hero-details__item')\n",
        "        runtime = runtime_tag.text.strip() if runtime_tag else 'N/A'\n",
        "\n",
        "        runtime_data.append({ 'Runtime': runtime})\n",
        "        time.sleep(1)  # Add delay to avoid being blocked\n",
        "\n",
        "    except Exception as e:\n",
        "\n",
        "        runtime_data.append({ 'Runtime': 'Error'})\n",
        "\n",
        "# Save the data to CSV\n",
        "df = pd.DataFrame(runtime_data)\n",
        "df.to_csv('/content/drive/My Drive/movie_runtime.csv', index=False)\n",
        "\n",
        "print(\"Runtimes have been scraped and saved to 'movie_runtime.csv'.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edb4gsNcRJQN"
      },
      "source": [
        "## **Scrapping Age Rating**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xScN7ENVcaxa"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Mount Google Drive (if in Google Colab)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the base URL and headers\n",
        "base_url = 'https://www.justwatch.com/in/movies?release_year_from=2000'\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'\n",
        "}\n",
        "\n",
        "# Fetch the main page\n",
        "response = requests.get(base_url, headers=headers)\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# Extract movie URLs\n",
        "movie_links = soup.find_all('a', href=True)\n",
        "movie_urls = [link['href'] for link in movie_links if '/movie/' in link['href']]\n",
        "url_list = ['https://www.justwatch.com' + x for x in movie_urls]\n",
        "\n",
        "# Scrape Age Ratings\n",
        "age_rating_data = []\n",
        "\n",
        "for movie_url in url_list:\n",
        "    try:\n",
        "        response = requests.get(movie_url, headers=headers)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Extract Age Rating\n",
        "        titleInfoTag = soup.find_all('div', class_='title-info')  # Fixed class name here\n",
        "\n",
        "        for tag in titleInfoTag:\n",
        "            divs = tag.find_all('div', class_='detail-infos')\n",
        "            for div in divs:\n",
        "                heading = div.find('h3', class_='detail-infos__subheading')\n",
        "                if heading and heading.text.strip() == 'Age rating':\n",
        "                    age_rating_div = div.find('div', class_='detail-infos__value')\n",
        "                    if age_rating_div:\n",
        "                        age_rating_data.append(age_rating_div.text.strip())\n",
        "                    else:\n",
        "                        age_rating_data.append('N/A')\n",
        "                    break\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error scraping {movie_url}: {e}\")\n",
        "        age_rating_data.append('N/A')\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame({'Age Rating': age_rating_data})\n",
        "\n",
        "# Save to CSV\n",
        "df.to_csv('/content/drive/My Drive/movie_age_rating.csv', index=False)\n",
        "\n",
        "print(\"Age Ratings have been scraped and saved to 'movie_age_rating.csv'.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RI5FD3CqFVV"
      },
      "source": [
        "## **Fetching Production Countries Details**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ai6YOgZmYIcc"
      },
      "outputs": [],
      "source": [
        "# Write Your Code here\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Base URL\n",
        "url = 'https://www.justwatch.com/in/movies?release_year_from=2000'\n",
        "\n",
        "# Headers\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'\n",
        "}\n",
        "\n",
        "# Step 1: Fetch Movie Links\n",
        "response = requests.get(url, headers=headers)\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# Extract movie URLs\n",
        "movie_links = soup.find_all('a', href=True)\n",
        "movie_urls = [link['href'] for link in movie_links if '/movie/' in link['href']]\n",
        "url_list = ['https://www.justwatch.com' + x for x in movie_urls]\n",
        "\n",
        "# Step 2: Fetch Production Countries\n",
        "production_country = []\n",
        "\n",
        "for movie_url in url_list:\n",
        "    response = requests.get(movie_url, headers=headers)\n",
        "    movie_soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    production_country_tag = movie_soup.find('div', class_='title-info')  # Find the main container\n",
        "\n",
        "    if production_country_tag:\n",
        "        detail_divs = production_country_tag.find_all('div', class_='detail-infos')  # Find all detail info divs\n",
        "        for detail_div in detail_divs:\n",
        "            heading = detail_div.find('h3', class_='detail-infos__subheading')  # Find the heading\n",
        "            if heading and heading.text.strip() == 'Production country':  # Check if heading exists and matches\n",
        "                production_country_div = detail_div.find('div', class_='detail-infos__value')\n",
        "                if production_country_div:\n",
        "                    production_country.append(production_country_div.text.strip())\n",
        "                else:\n",
        "                    production_country.append('N/A')  # Handle cases where production country is not found\n",
        "                break  # Exit the inner loop once found\n",
        "    else:\n",
        "        production_country.append('N/A')  # Handle cases where the main container is not found\n",
        "\n",
        "\n",
        "# Step 3: Save Data to CSV\n",
        "df = pd.DataFrame({ 'Production Country': production_country})\n",
        "output_path = '/content/drive/My Drive/movie_production_country.csv'\n",
        "df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"Production countries have been scraped and saved to '{output_path}'.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrJlIsBWrO2r"
      },
      "source": [
        "## **Fetching Streaming Service Details**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yk72jDLZu7EZ",
        "outputId": "94c0cd2c-fb4b-4291-8f96-45c95a51301d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Streaming Service have been scraped and saved to 'movie_streaming_service.csv'.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "url = 'https://www.justwatch.com/in/movies?release_year_from=2000'\n",
        "\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'\n",
        "}\n",
        "\n",
        "response = requests.get(url, headers=headers)\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "movie_links = soup.find_all('a', href=True)\n",
        "movie_urls = [link['href'] for link in movie_links if '/movie/' in link['href']]\n",
        "url_list = ['https://www.justwatch.com' + x for x in movie_urls]\n",
        "\n",
        "streaming_service = []\n",
        "\n",
        "for movie_url in url_list:\n",
        "    response = requests.get(movie_url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Find all offer tags (service_tags) for the current movie\n",
        "    service_tags = soup.find_all('a', class_='offer')  # Moved inside the loop\n",
        "    platforms = [tag.find('img')['alt'].strip() for tag in service_tags if tag.find('img')]\n",
        "\n",
        "    streaming_service.append(', '.join(platforms) if platforms else 'N/A')\n",
        "\n",
        "df = pd.DataFrame({'Streaming Service': streaming_service})\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df.to_csv('movie_streaming_service.csv', index=False)\n",
        "df.to_csv('/content/drive/My Drive/movie_streaming_service.csv.csv', index=False)\n",
        "\n",
        "print(\"Streaming Service have been scraped and saved to 'movie_streaming_service.csv'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mnh22VX_7f6K"
      },
      "source": [
        "## **Now Creating Movies DataFrame**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqJhgDY9uBtv"
      },
      "source": [
        "Feteching Movies_TiTles\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkF2K9n2rCPx",
        "outputId": "8f087ceb-917d-4c5b-88d0-0e2c57eaa603"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Movie titles have been scraped and saved to 'movie_titles.csv'.\n"
          ]
        }
      ],
      "source": [
        "from bs4 import BeautifulStoneSoup\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from google.colab import files\n",
        "\n",
        "url = 'https://www.justwatch.com/in/movies?release_year_from=2000'\n",
        "headers ={\n",
        "    'User-Agent': 'Mozilla/5.0(Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'\n",
        "}\n",
        "response = requests.get(url,headers=headers)\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# Find all movie links and build full URLs\n",
        "movie_links = soup.find_all('a', href=True)\n",
        "movie_urls = [link['href'] for link in movie_links if '/movie/' in link['href']]\n",
        "url_list = ['https://www.justwatch.com' + x for x in movie_urls]\n",
        "\n",
        "movies_titles = []\n",
        "\n",
        "for movie_url in url_list:\n",
        "    response = requests.get(movie_url,headers= headers)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Extract movie title\n",
        "    title_tag = soup.find('h1')\n",
        "    title = title_tag.text.strip() if title_tag else 'N/A'\n",
        "    movies_titles.append(title)\n",
        "\n",
        "df = pd.DataFrame({'Title': movies_titles})\n",
        "df.to_csv('/content/drive/My Drive/movie_titles.csv', index=False)\n",
        "\n",
        "print(\"Movie titles have been scraped and saved to 'movie_titles.csv'.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "di6ihHXmaerd",
        "outputId": "be1f3896-44c2-443e-f61a-4ea776bddc61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Check if the file exists before attempting to read it\n",
        "import os\n",
        "file_path = '/content/drive/My Drive/movie_titles.csv'  # Replace with the actual path if needed\n",
        "if not os.path.exists(file_path):\n",
        "  print(f\"Error: The file '{file_path}' does not exist. Please make sure it was created in the previous scraping step.\")\n",
        "else:\n",
        "    # Assuming you've already scraped and saved the data into these CSV files:\n",
        "    movie_titles_df = pd.read_csv(file_path)\n",
        "    movie_release_years_df = pd.read_csv('/content/drive/My Drive/movie_release_years.csv')\n",
        "    movie_genres_df = pd.read_csv('/content/drive/My Drive/movie_genres.csv')\n",
        "    movie_imdb_ratings_df = pd.read_csv('/content/drive/My Drive/movie_imdb_ratings.csv')\n",
        "    movie_runtime_df = pd.read_csv('/content/drive/My Drive/movie_runtime.csv')\n",
        "    movie_age_rating_df = pd.read_csv('/content/drive/My Drive/movie_age_rating.csv')\n",
        "    movie_production_country_df = pd.read_csv('/content/drive/My Drive/movie_production_country.csv')\n",
        "    movie_streaming_service_df = pd.read_csv('/content/drive/My Drive/movie_streaming_service.csv.csv')\n",
        "\n",
        "    # Concatenate (combine) the DataFrames horizontally\n",
        "    movies_df = pd.concat([ movie_titles_df, movie_release_years_df, movie_genres_df, movie_imdb_ratings_df,\n",
        "                           movie_runtime_df, movie_age_rating_df, movie_production_country_df,\n",
        "                           movie_streaming_service_df], axis=1)\n",
        "\n",
        "    # Display the first few rows of the DataFrame to check if it's correct\n",
        "    movies_df.head()\n",
        "\n",
        "    # Save the combined DataFrame to a new CSV file\n",
        "    movies_df.to_csv('/content/drive/My Drive/movies_data.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYQ5acWzJRZr"
      },
      "source": [
        "## **Scraping TV  Show Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VcRvbmQ-ZOIF",
        "outputId": "e4b65646-169a-41eb-b558-4774d6f2563b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Release years have been scraped and saved to '/content/drive/My Drive/tv_shows_data.csv'.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from google.colab import files\n",
        "\n",
        "tv_url = 'https://www.justwatch.com/in/tv-shows?release_year_from=2000'\n",
        "\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0(Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'\n",
        "}\n",
        "\n",
        "page = requests.get(tv_url, headers=headers)\n",
        "soup = BeautifulSoup(page.text, 'html.parser')\n",
        "\n",
        "tv_links = soup.find_all('a',href=True)\n",
        "tv_show_urls = [link['href'] for link in tv_links if '/tv-show/' in link['href']]\n",
        "full_tv_show_urls = ['https://www.justwatch.com' + url for url in tv_show_urls]\n",
        "\n",
        "tv_show_data = []\n",
        "for tv_show_url in full_tv_show_urls:\n",
        "    response = requests.get(tv_show_url, headers=headers)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Extract data\n",
        "    title = soup.find('h1', class_=\"title-detail-hero__details__title\").text.strip() if soup.find('h1', class_=\"title-detail-hero__details__title\") else 'N/A'\n",
        "    release_year = soup.find('span', class_='release-year').text.strip() if soup.find('span', class_='release-year') else 'N/A'\n",
        "    imdb_rating = soup.find('span', class_='imdb-score').text.strip().split(' ')[0] if soup.find('span', class_='imdb-score') else 'N/A'\n",
        "\n",
        "    # Extract streaming services\n",
        "    streaming_services = []\n",
        "    service_tags = soup.find_all('a', class_='offer')\n",
        "    for tag in service_tags:\n",
        "        img = tag.find('img')\n",
        "        service = img['alt'].strip() if 'alt' in img.attrs else 'N/A'\n",
        "        streaming_services.append(service)\n",
        "\n",
        "    # Initialize genre to 'N/A' before the try-except block\n",
        "    genre = 'N/A'\n",
        "\n",
        "    # Extract genre\n",
        "    try:\n",
        "        div = soup.find('div', class_='title-info')\n",
        "        if div:\n",
        "            detail_div = div.find_all('div', class_='detail-infos')[1]  # Adjust class as needed\n",
        "            if detail_div:\n",
        "                span_tags = detail_div.find_all('span')  # Find all <span> tags if genres are stored there\n",
        "                genre_list = []  # Initialize an empty list for genres\n",
        "                for tag in span_tags:\n",
        "                    genre = tag.text.strip()\n",
        "                    if genre:\n",
        "                        genre_list.append(genre)\n",
        "                # Join the genres into a comma-separated string\n",
        "                genre = ', '.join(genre_list)\n",
        "    except IndexError:\n",
        "        pass  # Handle the IndexError if it occurs\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting genre from {tv_show_url}: {e}\")  # Print the error for debugging\n",
        "\n",
        "\n",
        "    # Append all data for the current TV show as one dictionary\n",
        "    tv_show_data.append({\n",
        "        'Title': title,\n",
        "        'Release Year': release_year,\n",
        "        'IMDb Rating': imdb_rating,\n",
        "        'Genre': genre,  # Use the extracted genre value\n",
        "        'Streaming Services': ', '.join(streaming_services)\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(tv_show_data)\n",
        "\n",
        "output_path = '/content/drive/My Drive/tv_shows_data.csv'\n",
        "df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"Release years have been scraped and saved to '{output_path}'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ev-VUSNvJ-fJ"
      },
      "source": [
        "## **Fetching Tv shows Url details**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eMlwT4I-8gGh",
        "outputId": "b54ba604-0beb-4169-ce44-b7020b56e428"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "TV show URLs have been scraped and saved to '/content/drive/My Drive/tv_show_urls.csv'.\n",
            "                                        TV Show URLs\n",
            "0    https://www.justwatch.com/in/tv-show/squid-game\n",
            "1    https://www.justwatch.com/in/tv-show/paatal-lok\n",
            "2  https://www.justwatch.com/in/tv-show/solo-leve...\n",
            "3  https://www.justwatch.com/in/tv-show/thukra-ke...\n",
            "4  https://www.justwatch.com/in/tv-show/the-day-o...\n"
          ]
        }
      ],
      "source": [
        "# Write Your Code here\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from google.colab import files\n",
        "\n",
        "# URL for TV shows listing\n",
        "tv_url = 'https://www.justwatch.com/in/tv-shows?release_year_from=2000'\n",
        "\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0(Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'\n",
        "}\n",
        "\n",
        "page = requests.get(tv_url, headers=headers)\n",
        "soup = BeautifulSoup(page.text, 'html.parser')\n",
        "\n",
        "tv_links = soup.find_all('a',href=True)\n",
        "tv_show_urls = [link['href'] for link in tv_links if '/tv-show/' in link['href']]\n",
        "full_tv_show_urls = ['https://www.justwatch.com' + url for url in tv_show_urls]\n",
        "\n",
        "tv_show_Url_details_df = pd.DataFrame(full_tv_show_urls, columns=['TV Show URLs'])\n",
        "output_path = '/content/drive/My Drive/tv_show_urls.csv'\n",
        "tv_show_Url_details_df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"TV show URLs have been scraped and saved to '{output_path}'.\")\n",
        "print(tv_show_Url_details_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vZLzmqcKDPX"
      },
      "source": [
        "## **Fetching Tv Show Title details**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "a8Y6UF6-JLvO",
        "outputId": "224e888b-a231-4f1b-eb22-b0f4fadc4a11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "TV show titles have been scraped and saved to '/content/drive/My Drive/tv_show_titles.csv'.\n"
          ]
        }
      ],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from google.colab import files\n",
        "\n",
        "tv_url = 'https://www.justwatch.com/in/tv-shows?release_year_from=2000'\n",
        "\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0(Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'\n",
        "}\n",
        "\n",
        "page = requests.get(tv_url, headers=headers)\n",
        "soup = BeautifulSoup(page.text, 'html.parser')\n",
        "\n",
        "tv_links = soup.find_all('a',href=True)\n",
        "tv_show_urls = [link['href'] for link in tv_links if '/tv-show/' in link['href']]\n",
        "full_tv_show_urls = ['https://www.justwatch.com' + url for url in tv_show_urls]\n",
        "\n",
        "\n",
        "# List to store extracted data\n",
        "tv_show_details = []\n",
        "for tv_show_url in full_tv_show_urls:\n",
        "    response = requests.get(tv_show_url, headers=headers)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "\n",
        "\n",
        "    title_tag = soup.find('h1')\n",
        "\n",
        "    title = title_tag.text.strip() if title_tag else 'N/A'\n",
        "    tv_show_details.append(title)\n",
        "\n",
        "df = pd.DataFrame({'Title': tv_show_details})\n",
        "output_path = '/content/drive/My Drive/tv_show_titles.csv'\n",
        "df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"TV show titles have been scraped and saved to '{output_path}'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEIt9j6RKa9B"
      },
      "source": [
        "## **Fetching Release Year**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "r72fyiF8JozW",
        "outputId": "b98d8a04-ad5e-42ab-efe2-8f59c1efb1c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Release years have been scraped and saved to '/content/drive/My Drive/tv_show_release_years.csv'.\n"
          ]
        }
      ],
      "source": [
        "# Write Your Code here\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "\n",
        "tv_url = 'https://www.justwatch.com/in/tv-shows?release_year_from=2000'\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0(Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'\n",
        "}\n",
        "\n",
        "response = requests.get(tv_url,headers=headers)\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "tv_show_links = soup.find_all('a', href=True)\n",
        "tv_show_urls = [link['href'] for link in tv_show_links if '/tv-show/' in link['href']]\n",
        "full_tv_show_urls = ['https://www.justwatch.com' + url for url in tv_show_urls]\n",
        "\n",
        "\n",
        "# List to store release years\n",
        "release_years = []\n",
        "\n",
        "# Extract release year for each TV show\n",
        "for tv_show_url in full_tv_show_urls:\n",
        "    try:\n",
        "        response = requests.get(tv_show_url, headers=headers)\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Extract release year\n",
        "        year_tag = soup.find('span', class_='release-year')  # Adjust class if needed\n",
        "        release_year = year_tag.text.strip() if year_tag else 'N/A'\n",
        "\n",
        "        # Append to the list\n",
        "        release_years.append(release_year)\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {tv_show_url}: {e}\")\n",
        "        release_years.append('N/A')\n",
        "\n",
        "        # Create a DataFrame from the extracted data\n",
        "df = pd.DataFrame({'Release Year': release_years})\n",
        "\n",
        "\n",
        "output_path = '/content/drive/My Drive/tv_show_release_years.csv'\n",
        "df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"Release years have been scraped and saved to '{output_path}'.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P96pGO9kRCLv"
      },
      "source": [
        "## **Fetching TV Show Genre Details**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Jay8a9xgT43-",
        "outputId": "613e7b70-0ee3-417c-ceef-c3d0e5e3f9aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "TV show genres have been scraped and saved to '/content/drive/My Drive/tv_show_genres.csv'.\n"
          ]
        }
      ],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Base URL for TV show listings\n",
        "tv_url = 'https://www.justwatch.com/in/tv-shows?release_year_from=2000'\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'\n",
        "}\n",
        "\n",
        "# Fetch the main page\n",
        "response = requests.get(tv_url, headers=headers)\n",
        "if response.status_code != 200:\n",
        "    print(\"Failed to fetch the main page. Please check the URL or internet connection.\")\n",
        "    exit()\n",
        "\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# Find all TV show links and build full URLs\n",
        "tv_links = soup.find_all('a', href=True)\n",
        "tv_urls = [link['href'] for link in tv_links if '/tv-show/' in link['href']]\n",
        "tv_url_list = ['https://www.justwatch.com' + x for x in tv_urls]\n",
        "\n",
        "# Initialize list to store genres\n",
        "tv_genres = []\n",
        "\n",
        "# Scrape each TV show's genres\n",
        "for tv_url in tv_url_list:\n",
        "    try:\n",
        "        response = requests.get(tv_url, headers=headers)\n",
        "        if response.status_code != 200:\n",
        "            print(f\"Failed to fetch page: {tv_url}\")\n",
        "            tv_genres.append('N/A')\n",
        "            continue\n",
        "\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Find the div containing genres\n",
        "        div = soup.find('div', class_='title-info')  # Update the class if necessary based on actual site HTML\n",
        "\n",
        "        # Extract genres\n",
        "        genre_list = []\n",
        "        if div:\n",
        "            detail_div = div.find_all('div', class_='detail-infos')[1]  # Adjust class as needed\n",
        "            if detail_div:\n",
        "                span_tags = detail_div.find_all('span')  # Find all <span> tags if genres are stored there\n",
        "                for tag in span_tags:\n",
        "                    genre = tag.text.strip()\n",
        "                    if genre:\n",
        "                        genre_list.append(genre)\n",
        "\n",
        "        # Handle case where no genres are found\n",
        "        if not genre_list:\n",
        "            genre_list.append('N/A')\n",
        "\n",
        "        # Append the genres as a comma-separated string\n",
        "        tv_genres.append(', '.join(genre_list))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while processing {tv_url}: {e}\")\n",
        "        tv_genres.append('N/A')\n",
        "\n",
        "# Create DataFrame and save to CSV\n",
        "df_tv_genres = pd.DataFrame({'Genre': tv_genres})\n",
        "csv_path = '/content/drive/My Drive/tv_show_genres.csv'\n",
        "df_tv_genres.to_csv(csv_path, index=False)\n",
        "\n",
        "print(f\"TV show genres have been scraped and saved to '{csv_path}'.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hk3eSdDAXQv8"
      },
      "source": [
        "## **Fetching IMDB Rating Details**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmltFOQEXM2W",
        "outputId": "433310d4-fb3b-43ed-abde-04f9ff2faacf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "IMDB ratings have been scraped and saved to '/content/drive/My Drive/tv_show_imdb_ratings.csv'.\n"
          ]
        }
      ],
      "source": [
        "# Write Your Code here\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from google.colab import files\n",
        "\n",
        "tv_url = 'https://www.justwatch.com/in/tv-shows?release_year_from=2000'\n",
        "\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0(Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'\n",
        "}\n",
        "\n",
        "page = requests.get(tv_url, headers=headers)\n",
        "soup = BeautifulSoup(page.text, 'html.parser')\n",
        "\n",
        "# Find all TV show links and build full URLs\n",
        "tv_links = soup.find_all('a',href=True)\n",
        "tv_show_urls = [link['href'] for link in tv_links if '/tv-show/' in link['href']]\n",
        "full_tv_show_urls = ['https://www.justwatch.com' + url for url in tv_show_urls]\n",
        "\n",
        "\n",
        "# List to store extracted data\n",
        "tv_imdb_ratings = []\n",
        "for tv_show_url in full_tv_show_urls:\n",
        "    try:\n",
        "        response = requests.get(tv_show_url, headers=headers)\n",
        "        soup = BeautifulSoup(response.text,'html.parser')\n",
        "        # Find the IMDB rating\n",
        "        rating_tag = soup.find('span', class_='imdb-score')\n",
        "        imdb_rating = rating_tag.text.strip().split(' ')[0] if rating_tag else 'N/A'\n",
        "\n",
        "        tv_imdb_ratings.append(imdb_rating)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {tv_url}: {e}\")\n",
        "        tv_imdb_ratings.append('N/A')\n",
        "\n",
        "\n",
        "\n",
        "        # Create a DataFrame from the extracted data\n",
        "df = pd.DataFrame({'IMDB Rating': tv_imdb_ratings})\n",
        "\n",
        "output_path = '/content/drive/My Drive/tv_show_imdb_ratings.csv'\n",
        "df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"IMDB ratings have been scraped and saved to '{output_path}'.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZ9nJhmiZB_W"
      },
      "source": [
        "## **Fetching Age Rating Details**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlKCu7gma-Y5",
        "outputId": "36390a03-cda5-4abc-d8c7-558db07d4410"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Age ratings have been scraped and saved to '/content/drive/My Drive/tv_show_age_rating.csv'.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "tv_url = 'https://www.justwatch.com/in/tv-shows?release_year_from=2000'\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'\n",
        "}\n",
        "\n",
        "# Fetch the main page\n",
        "response = requests.get(tv_url, headers=headers)\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "tv_links = soup.find_all('a', href=True)\n",
        "tv_urls = [link['href'] for link in tv_links if '/tv-show/' in link['href']]\n",
        "tv_url_list = ['https://www.justwatch.com' + x for x in tv_urls]\n",
        "\n",
        "tv_show_age_ratings = []\n",
        "\n",
        "for tv_url in tv_url_list:\n",
        "    response = requests.get(tv_url, headers=headers)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    age_rating = 'N/A'  # Default value if not found\n",
        "    age_rating_tag = soup.find('div', class_='title-info')\n",
        "\n",
        "    if age_rating_tag:\n",
        "        divs = age_rating_tag.find_all('div', class_='detail-infos')\n",
        "        for div in divs:\n",
        "            heading = div.find('h3', class_='detail-infos__subheading')\n",
        "            if heading and heading.text.strip() == 'Age rating':\n",
        "                age_rating_div = div.find('div', class_='detail-infos__value')\n",
        "                if age_rating_div:\n",
        "                    age_rating = age_rating_div.text.strip()\n",
        "                break  # Exit the loop once found\n",
        "\n",
        "    tv_show_age_ratings.append(age_rating)\n",
        "\n",
        "df = pd.DataFrame({'Age Rating': tv_show_age_ratings})\n",
        "output_path = '/content/drive/My Drive/tv_show_age_rating.csv'\n",
        "df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"Age ratings have been scraped and saved to '{output_path}'.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ii49LH4tdNoN"
      },
      "source": [
        "## **Fetching Production Country details**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xihOeyN8XXDt",
        "outputId": "1a0d6abc-fa1e-44b2-9925-afac0eb13db2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Production countries for TV shows have been scraped and saved to 'tv_show_production_country.csv'.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from google.colab import files\n",
        "\n",
        "# Base URL for TV show listings (if not already defined)\n",
        "tv_url = 'https://www.justwatch.com/in/tv-shows?release_year_from=2000'\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'\n",
        "}\n",
        "\n",
        "response = requests.get(tv_url, headers=headers)\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "tv_links = soup.find_all('a', href=True)\n",
        "tv_urls = [link['href'] for link in tv_links if '/tv-show/' in link['href']]\n",
        "tv_url_list = ['https://www.justwatch.com' + x for x in tv_urls]\n",
        "\n",
        "tv_production_country_data = []\n",
        "\n",
        "for tv_url in tv_url_list:\n",
        "    response = requests.get(tv_url, headers=headers)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    # Find the production country information\n",
        "    production_country_tag = soup.find('div', class_='title-info')\n",
        "    if production_country_tag:\n",
        "        detail_divs = production_country_tag.find_all('div', class_='detail-infos')\n",
        "        for detail_div in detail_divs:\n",
        "            heading = detail_div.find('h3', class_='detail-infos__subheading')\n",
        "            if heading and heading.text.strip() == 'Production country':\n",
        "                production_country_div = detail_div.find('div', class_='detail-infos__value')\n",
        "                if production_country_div:\n",
        "                    tv_production_country_data.append(production_country_div.text.strip())\n",
        "                else:\n",
        "                    tv_production_country_data.append('N/A')\n",
        "                break  # Exit the inner loop once found\n",
        "    else:\n",
        "        tv_production_country_data.append('N/A')\n",
        "\n",
        "# Create a DataFrame and save to CSV\n",
        "df = pd.DataFrame({'Production Country': tv_production_country_data})\n",
        "df.to_csv('/content/drive/My Drive/tv_show_production_country.csv', index=False)\n",
        "\n",
        "print(\"Production countries for TV shows have been scraped and saved to 'tv_show_production_country.csv'.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHZwwgiKdlQm"
      },
      "source": [
        "## **Fetching Streaming Service details**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MBl6Vqadrl9",
        "outputId": "e9561ee8-8245-445b-b5d7-8305cdd4840b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Streaming Service have been scraped and saved to 'tv_show_streaming_service.csv'.\n"
          ]
        }
      ],
      "source": [
        "# Write Your Code here\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from bs4 import BeautifulSoup\n",
        "from google.colab import files\n",
        "\n",
        "# Base URL for TV show listings (if not already defined)\n",
        "tv_url = 'https://www.justwatch.com/in/tv-shows?release_year_from=2000'\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'\n",
        "}\n",
        "\n",
        "response = requests.get(tv_url, headers=headers)\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "tv_links = soup.find_all('a', href=True)\n",
        "tv_urls = [link['href'] for link in tv_links if '/tv-show/' in link['href']]\n",
        "tv_url_list = ['https://www.justwatch.com' + x for x in tv_urls]\n",
        "\n",
        "streaming_services = []  # Corrected variable name\n",
        "\n",
        "for tv_url in tv_url_list:\n",
        "    response = requests.get(tv_url, headers=headers)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Find all offer tags (service_tags) for the current TV show\n",
        "    service_tags = soup.find_all('a', class_='offer')\n",
        "    platforms = [tag.find('img')['alt'].strip() for tag in service_tags if tag.find('img')]\n",
        "\n",
        "    streaming_services.append(', '.join(platforms) if platforms else 'N/A') #Append list into platforms\n",
        "\n",
        "df = pd.DataFrame({'Streaming Service': streaming_services}) # Corrected variable name\n",
        "df.to_csv('/content/drive/My Drive/tv_show_streaming_service.csv', index=False)\n",
        "\n",
        "print(\"Streaming Service have been scraped and saved to 'tv_show_streaming_service.csv'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUOtDJv9gM4a"
      },
      "source": [
        "## **Fetching Duration Details**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4x4YY6AfoL1",
        "outputId": "af194fb4-a713-4578-ef67-034e40545aa9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "TV show durations have been scraped and saved to 'tv_show_duration.csv'.\n"
          ]
        }
      ],
      "source": [
        "# Write Your Code here\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "tv_url = 'https://www.justwatch.com/in/tv-shows?release_year_from=2000'\n",
        "\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0(Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'\n",
        "}\n",
        "\n",
        "page = requests.get(tv_url, headers=headers)\n",
        "soup = BeautifulSoup(page.text, 'html.parser')\n",
        "\n",
        "# Find all TV show links and build full URLs\n",
        "tv_links = soup.find_all('a',href=True)\n",
        "tv_show_urls = [link['href'] for link in tv_links if '/tv-show/' in link['href']]\n",
        "full_tv_show_urls = ['https://www.justwatch.com' + url for url in tv_show_urls]\n",
        "\n",
        "\n",
        "# Initialize list to store TV show durations\n",
        "tv_show_duration = []\n",
        "\n",
        "# Loop through individual TV show URLs:\n",
        "for tv_show_url in full_tv_show_urls:  # Use the correct variable\n",
        "    try:\n",
        "\n",
        "        response = requests.get(tv_show_url, headers=headers)\n",
        "        if response.status_code == 200:\n",
        "          soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "          # Find the element containing duration information\n",
        "          runtime_tag = soup.find('div', class_='title-detail-hero-details__item')\n",
        "\n",
        "          # Extract duration, handling cases where it's not found\n",
        "          runtime = runtime_tag.text.strip().split()[0] if runtime_tag and runtime_tag.text.strip() else 'N/A'\n",
        "          tv_show_duration.append({'Runtime': runtime})\n",
        "        else:\n",
        "          print(f\"Failed to fetch {tv_show_url}: HTTP {response.status_code}\")\n",
        "          tv_show_duration.append({'Runtime': 'Error'})\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error scraping {tv_show_url}: {e}\")  # Correct URL for error message\n",
        "        tv_show_duration.append({'Runtime': 'Error'})\n",
        "\n",
        "\n",
        "# Create a DataFrame and save to CSV\n",
        "df = pd.DataFrame(tv_show_duration)\n",
        "df.to_csv('/content/drive/My Drive/tv_show_duration.csv', index=False)\n",
        "\n",
        "print(\"TV show durations have been scraped and saved to 'tv_show_duration.csv'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nD4QVPT-nfVR"
      },
      "source": [
        "## **Creating TV Show DataFrame**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3Lnlb-xip2U",
        "outputId": "b66aaea6-9756-45ea-8b3a-c6d033d6380e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "tv_show_titles_df = pd.read_csv('/content/drive/My Drive/tv_show_titles.csv')\n",
        "tv_show_release_years_df = pd.read_csv('/content/drive/My Drive/tv_show_release_years.csv')\n",
        "tv_show_genres_df = pd.read_csv('/content/drive/My Drive/tv_show_genres.csv')\n",
        "tv_show_imdb_ratings_df = pd.read_csv('/content/drive/My Drive/tv_show_imdb_ratings.csv')\n",
        "tv_show_age_rating_df = pd.read_csv('/content/drive/My Drive/tv_show_age_rating.csv')\n",
        "tv_show_production_country_df = pd.read_csv('/content/drive/My Drive/tv_show_production_country.csv')\n",
        "tv_show_streaming_service_df = pd.read_csv('/content/drive/My Drive/tv_show_streaming_service.csv')\n",
        "tv_show_duration_df = pd.read_csv('/content/drive/My Drive/tv_show_duration.csv')\n",
        "\n",
        "tv_shows_df = pd.concat([tv_show_titles_df, tv_show_release_years_df, tv_show_genres_df,\n",
        "                         tv_show_imdb_ratings_df, tv_show_age_rating_df, tv_show_production_country_df,\n",
        "                         tv_show_streaming_service_df, tv_show_duration_df], axis=1)\n",
        "tv_shows_df.head()\n",
        "\n",
        "tv_shows_df.to_csv('/content/drive/My Drive/tv_shows_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyqHHKh4IDx6"
      },
      "source": [
        "## **Task 2 :- Data Filtering & Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxIG3uv1sFUE",
        "outputId": "d6f2ba28-f4bd-4e94-e823-7f4b3276456b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: 'Streaming Service' column not found in one or both DataFrames. Skipping streaming service analysis.\n",
            "Filtered movies and TV shows have been saved successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-dc78c3aa4b8b>:10: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  movies_df['release_year'] = pd.to_datetime(movies_df['release_year'], errors='coerce')\n",
            "<ipython-input-19-dc78c3aa4b8b>:11: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  tv_shows_df['Release Year'] = pd.to_datetime(tv_shows_df['Release Year'], errors='coerce')\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "movies_df = pd.read_csv('/content/drive/My Drive/movies_data.csv')\n",
        "tv_shows_df = pd.read_csv('/content/drive/My Drive/tv_shows_data.csv')\n",
        "\n",
        "two_years_ago = datetime.now() - timedelta(days=730)  # Calculate the date two years ago\n",
        "\n",
        "# Convert 'release_year' and 'Release Year' to datetime objects before filtering\n",
        "movies_df['release_year'] = pd.to_datetime(movies_df['release_year'], errors='coerce')\n",
        "tv_shows_df['Release Year'] = pd.to_datetime(tv_shows_df['Release Year'], errors='coerce')\n",
        "\n",
        "filtered_movies = movies_df[movies_df['release_year'] > two_years_ago]\n",
        "filtered_tv_shows = tv_shows_df[tv_shows_df['Release Year'] > two_years_ago]\n",
        "\n",
        "# Convert 'IMDb Rating' to numeric before filtering\n",
        "filtered_movies['IMDb Rating'] = pd.to_numeric(filtered_movies['IMDb Rating'], errors='coerce')\n",
        "filtered_tv_shows['IMDb Rating'] = pd.to_numeric(filtered_tv_shows['IMDb Rating'], errors='coerce')\n",
        "\n",
        "filtered_movies = filtered_movies[filtered_movies['IMDb Rating'] >= 7]\n",
        "filtered_tv_shows = filtered_tv_shows[filtered_tv_shows['IMDb Rating'] >= 7]\n",
        "\n",
        "avg_movie_rating = filtered_movies['IMDb Rating'].astype(float).mean()\n",
        "avg_tv_show_rating = filtered_tv_shows['IMDb Rating'].astype(float).mean()\n",
        "\n",
        "all_genres = pd.concat([filtered_movies['Genre'], filtered_tv_shows['Genre']]).dropna()\n",
        "top_genres = all_genres.value_counts().head(5)\n",
        "\n",
        "# Check if the column 'Streaming Service' exists in both DataFrames\n",
        "# Print a warning message and continue if not found\n",
        "if 'Streaming Service' not in filtered_movies.columns or 'Streaming Service' not in filtered_tv_shows.columns:\n",
        "    print(\"Warning: 'Streaming Service' column not found in one or both DataFrames. Skipping streaming service analysis.\")\n",
        "else:\n",
        "    all_streaming_services = pd.concat([filtered_movies['Streaming Service'], filtered_tv_shows['Streaming Service']]).dropna()\n",
        "    top_streaming_service = all_streaming_services.value_counts().idxmax()\n",
        "\n",
        "\n",
        "movies_df = pd.concat([movies_df, filtered_movies], axis=0)\n",
        "tv_shows_df = pd.concat([tv_shows_df, filtered_tv_shows], axis=0)\n",
        "\n",
        "movies_df.to_csv('/content/drive/My Drive/filtered_movies.csv', index=False)\n",
        "tv_shows_df.to_csv('/content/drive/My Drive/filtered_tv_shows.csv', index=False)\n",
        "\n",
        "print(\"Filtered movies and TV shows have been saved successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_OroblUQG4r"
      },
      "source": [
        "## **Analyzing Top Genres**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ljPnIn2LJLZ"
      },
      "outputs": [],
      "source": [
        "# Write Your Code here\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "from collections import Counter\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load data\n",
        "movies_df = pd.read_csv('/content/drive/My Drive/movies_data.csv')\n",
        "tv_shows_df = pd.read_csv('/content/drive/My Drive/tv_shows_data.csv')\n",
        "\n",
        "# Function to analyze top genres for a DataFrame\n",
        "def analyze_top_genres(df, top_n=5):\n",
        "    genre_counts = Counter()\n",
        "    for genre_string in df['Genre']:\n",
        "        if isinstance(genre_string, str):\n",
        "            genres = genre_string.split(', ')\n",
        "            genre_counts.update(genres)\n",
        "    return genre_counts.most_common(top_n)\n",
        "\n",
        "# Analyze top movie genres\n",
        "top_movie_genres = analyze_top_genres(movies_df)\n",
        "print(\"Top Movie Genres:\")\n",
        "for genre, count in top_movie_genres:\n",
        "    print(f\"- {genre}: {count}\")\n",
        "\n",
        "# Analyze top TV show genres\n",
        "top_tv_show_genres = analyze_top_genres(tv_shows_df)\n",
        "print(\"\\nTop TV Show Genres:\")\n",
        "for genre, count in top_tv_show_genres:\n",
        "    print(f\"- {genre}: {count}\")\n",
        "\n",
        "# Create a DataFrame for top genres\n",
        "top_genres_df = pd.DataFrame({\n",
        "    'Movie Genres': [genre for genre, count in top_movie_genres],\n",
        "    'Movie Counts': [count for genre, count in top_movie_genres],\n",
        "    'TV Show Genres': [genre for genre, count in top_tv_show_genres],\n",
        "    'TV Show Counts': [count for genre, count in top_tv_show_genres]\n",
        "})\n",
        "\n",
        "# Save to CSV\n",
        "top_genres_df.to_csv('/content/drive/My Drive/analyz_top_genre.csv', index=False)\n",
        "print(\"\\nTop genres have been analyzed and saved to 'analyz_top_genre.csv'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUPye0P0QP5I"
      },
      "source": [
        "## **Finding Predominant Streaming Service**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLXiCZSAO_40"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load movie and TV show data\n",
        "movies_df = pd.read_csv('/content/drive/My Drive/movies_data.csv')\n",
        "tv_shows_df = pd.read_csv('/content/drive/My Drive/tv_shows_data.csv')\n",
        "\n",
        "# Combine both datasets\n",
        "all_content_df = pd.concat([movies_df, tv_shows_df], ignore_index=True)\n",
        "\n",
        "# Ensure 'Streaming Service' column is properly split and exploded\n",
        "all_content_df['Streaming Service'] = all_content_df['Streaming Service'].str.split(', ')\n",
        "all_content_df = all_content_df.explode('Streaming Service')\n",
        "\n",
        "# Group by streaming service and count occurrences\n",
        "service_counts = all_content_df.groupby('Streaming Service')['Title'].count().reset_index()\n",
        "\n",
        "# Rename columns for clarity\n",
        "service_counts.rename(columns={'Streaming Service': 'Service', 'Title': 'Count'}, inplace=True)\n",
        "\n",
        "# Sort by count in descending order\n",
        "service_counts = service_counts.sort_values('Count', ascending=False)\n",
        "\n",
        "# Find the predominant streaming service\n",
        "predominant_service = service_counts.iloc[0]['Service']\n",
        "\n",
        "pridominant_service_df = pd.DataFrame({'Predominant Streaming Service': [predominant_service]})\n",
        "\n",
        "pridominant_service_df.to_csv('/content/drive/My Drive/predominant_streaming_service.csv', index=False)\n",
        "print(f\"The predominant streaming service is: {predominant_service}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tytqsADVR2x6"
      },
      "source": [
        "## **Task 3 :- Data Export**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvUJo5k7Ah08",
        "outputId": "4963c5a9-0524-4c24-83db-9e1b17ad5d23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered movies and TV shows have been saved successfully.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Load the datasets\n",
        "movie_df = pd.read_csv('/content/drive/My Drive/movies_data.csv')\n",
        "tv_shows_df = pd.read_csv('/content/drive/My Drive/tv_shows_data.csv')\n",
        "\n",
        "# Define the two-year cutoff\n",
        "two_years_ago = datetime.now().year - 2\n",
        "\n",
        "# Helper function to safely convert series to numeric\n",
        "def safe_numeric(series):\n",
        "    return pd.to_numeric(series, errors='coerce')\n",
        "\n",
        "# Ensure 'release_year' and 'Release Year' are strings\n",
        "movie_df['release_year'] = movie_df['release_year'].astype(str)\n",
        "tv_shows_df['Release Year'] = tv_shows_df['Release Year'].astype(str)\n",
        "\n",
        "# Extract the year using regex and convert to numeric\n",
        "movie_df['release_year'] = safe_numeric(movie_df['release_year'].str.extract(r'(\\d{4})')[0])\n",
        "tv_shows_df['Release Year'] = safe_numeric(tv_shows_df['Release Year'].str.extract(r'(\\d{4})')[0])\n",
        "\n",
        "# Filter movies released in the last two years with IMDb Rating >= 7\n",
        "filtered_movies = movie_df[\n",
        "    (movie_df['release_year'] >= two_years_ago) &\n",
        "    (safe_numeric(movie_df['IMDb Rating']) >= 7)\n",
        "].dropna(subset=['release_year', 'IMDb Rating'])  # Drop rows with NaN in critical columns\n",
        "\n",
        "# Filter TV shows released in the last two years with IMDb Rating >= 7\n",
        "filtered_movies = movie_df[\n",
        "    (movie_df['release_year'].astype(str).str.isdigit()) & (movie_df['release_year'].astype(int) >= two_years_ago) &\n",
        "    (safe_numeric(movie_df['IMDb Rating']) >= 7)\n",
        "].dropna(subset=['release_year', 'IMDb Rating'])\n",
        "\n",
        "\n",
        "# Save filtered data to CSV files\n",
        "filtered_movies.to_csv('/content/drive/My Drive/filtered_movies.csv', index=False)\n",
        "filtered_tv_shows.to_csv('/content/drive/My Drive/filtered_tv_shows.csv', index=False)\n",
        "\n",
        "print(\"Filtered movies and TV shows have been saved successfully.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6F3wrlGWOcl"
      },
      "source": [
        "# **Dataset Drive Link (View Access with Anyone) -**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9s-10dFhWZf4"
      },
      "source": [
        "# ***Congratulations!!! You have completed your Assignment.***"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "V-qsNrtIsBEp",
        "VEg1U1uPzGoj",
        "aqzhL8STqaMX",
        "UOof6-0xFuf6",
        "8CHiu0A5RAuM",
        "edb4gsNcRJQN",
        "_RI5FD3CqFVV",
        "IrJlIsBWrO2r",
        "Mnh22VX_7f6K",
        "1vZLzmqcKDPX",
        "mEIt9j6RKa9B",
        "P96pGO9kRCLv",
        "hk3eSdDAXQv8",
        "XZ9nJhmiZB_W",
        "ii49LH4tdNoN",
        "mHZwwgiKdlQm",
        "uUOtDJv9gM4a",
        "nD4QVPT-nfVR",
        "CyqHHKh4IDx6",
        "0bPDbn-gPyfm",
        "N_OroblUQG4r",
        "BUPye0P0QP5I",
        "tytqsADVR2x6"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}