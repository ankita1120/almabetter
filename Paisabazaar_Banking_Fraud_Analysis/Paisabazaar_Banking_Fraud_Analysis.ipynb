{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZ0i2xErY83g"
      },
      "source": [
        "#Project name - Paisabazaar Banking Fraud Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fZuaUJ6ZOCe"
      },
      "source": [
        " **Project type - Exploratory Data Analysis(EDA)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWP_LEItZkgQ"
      },
      "source": [
        "# Problem Statement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQHGNlGNZeLR"
      },
      "source": [
        "Objective:\n",
        "The objective of this analysis is to detect fraudulent activities in banking transactions and financial behaviors using customer data. This involves identifying key risk factors related to credit score, delayed payments, outstanding debt, credit utilization, and spending behavior.\n",
        "\n",
        "Challenges in Banking Fraud Detection:\n",
        "Fraudulent customers may manipulate credit behavior to appear genuine.\n",
        "High-risk customers may have poor credit scores, high outstanding debts, or frequent delayed payments.\n",
        "Fraudulent activities can arise due to excessive credit utilization and unusual spending patterns.\n",
        "\n",
        "Key Analysis Areas:\n",
        "Credit Risk Factors\n",
        "\n",
        "Customers with poor credit scores and excessive debt.\n",
        "Patterns in credit utilization ratio and delayed payments.\n",
        "Payment & Spending Behavior Analysis\n",
        "\n",
        "Identifying customers with risky spending habits (e.g., high spending with low income).\n",
        "Understanding different payment behaviors (e.g., minimum payments vs. full payments).\n",
        "Anomaly Detection for Fraudulent Activities\n",
        "\n",
        "Finding outliers in financial transactions.\n",
        "Identifying unusual loan application trends and banking activities.\n",
        "Predictive Fraud Detection Model (if applicable)\n",
        "\n",
        "Using machine learning to classify customers as fraudulent or non-fraudulent.\n",
        "Finding correlations between income, credit score, loan amount, and fraud likelihood.\n",
        "Expected Outcome:\n",
        "A data-driven risk assessment model that can flag high-risk customers.\n",
        "Insights into fraudulent patterns in banking transactions.\n",
        "A potential predictive model to help Paisabazaar prevent financial fraud."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUGJnkwKaP42"
      },
      "source": [
        "# EDA_Paisabazaar Banking Fraud Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BW43NNw5agRi"
      },
      "source": [
        "1.Know your Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-dU2n7uam1V"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.impute import SimpleImputer\n",
        "from scipy import stats\n",
        "from google.colab import drive\n",
        "import plotly.express as px\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jn9EJiNJbuvk"
      },
      "source": [
        "# Uploading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5ggHZnodLHm"
      },
      "outputs": [],
      "source": [
        "file_path = '/content/drive/My Drive/Colab Notebooks/Paisabazaar Banking Fraud Analysis.csv'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VqLnFu2dUNH"
      },
      "source": [
        "# Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pe9uCd54dXGA"
      },
      "outputs": [],
      "source": [
        "df_file = pd.read_csv(file_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RcE5xoMfQYc"
      },
      "source": [
        "# Dataset first Row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8xVE2nXfMtR"
      },
      "outputs": [],
      "source": [
        "df_file.head()\n",
        "print(df_file.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0c0W0MLsEsf"
      },
      "source": [
        "# Get information\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJn0s5KvsMy2"
      },
      "outputs": [],
      "source": [
        "# Get information about the data types and missing values\n",
        "print(df_file.info())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2p101r_QsR-y"
      },
      "source": [
        "# Get descriptive statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qusLo1IUsWGk"
      },
      "outputs": [],
      "source": [
        "# Get descriptive statistics for numerical columns\n",
        "print(df_file.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpqGzmwNfq6U"
      },
      "source": [
        "# Missing Values And Duplicate Row\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qU9XSjhgS2W"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3HtobzffqOF"
      },
      "outputs": [],
      "source": [
        "print(\"\\nDuplicate Rows:\", df_file.duplicated().sum())\n",
        "print(\"\\nMissing Values:\\n\", df_file.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjylRTTrglNo"
      },
      "source": [
        "# # 2. Handling Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHY-lc2lgvaA"
      },
      "outputs": [],
      "source": [
        "# 2. Handling Missing Values\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "\n",
        "# Select only numerical features for imputation\n",
        "numerical_features = df_file.select_dtypes(include=np.number).columns\n",
        "\n",
        "# Apply imputation to numerical features only\n",
        "df_file[numerical_features] = imputer.fit_transform(df_file[numerical_features])\n",
        "\n",
        "#Checking Data Types and Unique Values\n",
        "print(\"\\nColumn Data Types:\\n\", df_file.dtypes)\n",
        "print(\"\\nUnique Values per Column:\\n\", df_file.nunique())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7ZG7TpEhX1y"
      },
      "source": [
        "# 3. Handling Outliers using IQR Method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BD9b6C1HhbXS"
      },
      "outputs": [],
      "source": [
        "# Handling missing values\n",
        "# Select only numerical features for outlier handling\n",
        "numerical_features = df_file.select_dtypes(include=np.number).columns\n",
        "df_numeric = df_file[numerical_features]\n",
        "\n",
        "# Calculate quantiles and IQR for numerical features only\n",
        "Q1 = df_numeric.quantile(0.25)\n",
        "Q3 = df_numeric.quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Identify outliers in numerical features\n",
        "outlier_condition = (df_numeric < (Q1 - 1.5 * IQR)) | (df_numeric > (Q3 + 1.5 * IQR))\n",
        "\n",
        "# Remove rows with outliers from the original DataFrame\n",
        "df = df_file[~outlier_condition.any(axis=1)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bBg3MwnlUJD"
      },
      "source": [
        "# 4. Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IokbRp7Ylbnt"
      },
      "outputs": [],
      "source": [
        "# 4. Visualization\n",
        "plt.figure(figsize=(10, 6))\n",
        "# Replace 'Annual_Income' with the desired column name for visualization\n",
        "sns.histplot(df['Annual_Income'], bins=30, kde=True)\n",
        "plt.title(\"Distribution of Annual_Income\") # Update title accordingly\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeA8DskRmthD"
      },
      "source": [
        "# Correlation Heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfJ_OTRhmpp7"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "# Calculate correlation only for numerical features\n",
        "numerical_features = df.select_dtypes(include=np.number).columns\n",
        "correlation_matrix = df[numerical_features].corr()\n",
        "\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
        "plt.title(\"Feature Correlation Heatmap\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65DT31IBnrc4"
      },
      "source": [
        "# Pairplot for Relationship\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "E3JUU63kntNo"
      },
      "outputs": [],
      "source": [
        "numeric_cols = df_file.select_dtypes(include=[np.number]).columns\n",
        "if len(numeric_cols) > 1:\n",
        "    sample_df = df_file[numeric_cols].sample(n=min(500, len(df)), random_state=42)  # Limit to 500 samples if dataset is large\n",
        "    sns.pairplot(sample_df)\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Not enough numeric features for a pairplot.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4V6aXFx8pNdx"
      },
      "source": [
        "# # Interactive Scatter Matrix with Plotly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5GxCMTrq7ZN"
      },
      "outputs": [],
      "source": [
        "# Interactive Scatter Matrix with Plotly\n",
        "fig = px.scatter_matrix(df, dimensions=df.select_dtypes(include=[np.number]).columns)\n",
        "fig.update_layout(title=\"Scatter Matrix of Numeric Features\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZuzpRQpqwPK"
      },
      "source": [
        "# Interactive Boxplot for Outliers Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3l_OwZMqwtF"
      },
      "outputs": [],
      "source": [
        "# Interactive Boxplot for Outliers Detection\n",
        "fig = px.box(df, y=df.select_dtypes(include=[np.number]).columns, title=\"Interactive Boxplot for Outlier Detection\")\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ImDCdINrYWD"
      },
      "source": [
        "# # Interactive Bar Chart for Categorical Data Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NigSmq9JrY7B"
      },
      "outputs": [],
      "source": [
        "# Interactive Bar Chart for Categorical Data Distribution\n",
        "categorical_columns = df_file.select_dtypes(include=['object']).columns\n",
        "for col in categorical_columns:\n",
        "    # Get value counts and reset index\n",
        "    value_counts_df = df_file[col].value_counts().reset_index()\n",
        "    # Use the actual column names from the value_counts_df - 'index' for x and col for y\n",
        "    fig = px.bar(value_counts_df, x='index', y='count', title=f\"Distribution of {col}\") # Changed y=col to y='count'\n",
        "    fig.update_xaxes(title_text=col) # Set x-axis label to the original column name\n",
        "    fig.show()\n",
        "\n",
        "print(\"\\nExploratory Data Analysis Completed Successfully!\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}